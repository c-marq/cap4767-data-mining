{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-marq/cap4767-data-mining/blob/main/labs/lab03_churn_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GCoyGlcsPXH"
      },
      "source": [
        "# Lab 3 ‚Äî Churn Prediction: Full Pipeline\n",
        "**CAP4767 Data Mining with Python** | Miami Dade College ‚Äî Kendall Campus\n",
        "\n",
        "**Points:** 20 | **Format:** Individual | **Due:** End of Week 4\n",
        "\n",
        "| Part | Skills (Chapter) | Points |\n",
        "|------|-----------------|--------|\n",
        "| A: EDA | Cram√©r's V, Mann-Whitney U, business cost (Ch. 4) | 4 |\n",
        "| B: Logistic Regression | Baseline model + coefficient interpretation (Ch. 4) | 3 |\n",
        "| C: Neural Network | Keras ANN + dropout + early stopping (Ch. 5) | 4 |\n",
        "| D: Model Comparison | ROC curves + metrics table (Ch. 5) | 3 |\n",
        "| E: Written Analysis | Business recommendation (300+ words) | 4 |\n",
        "| F: Preprocessing | Pipeline runs correctly | 2 |\n",
        "| Bonus | Third model variant | +3 |\n",
        "\n",
        "<div style=\"background-color: #D6EAF8; border-left: 5px solid #2E86C1; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1A5276;\">üí° GRADING PHILOSOPHY</strong><br>\n",
        "  This lab rewards <strong>process over perfection</strong>. If your ANN performs <em>worse</em> than logistic regression, that's a valid result ‚Äî your written analysis should explain why.\n",
        "</div>\n",
        "\n",
        "<div style=\"background-color: #FEF9E7; border-left: 5px solid #F1C40F; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #7D6608;\">‚ö†Ô∏è IMPORTANT</strong><br>\n",
        "  Do NOT use the Telco dataset from class. You must use one of the two options below. Using the Telco dataset = <strong>-5 point deduction</strong>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAbK_SebsPXI"
      },
      "source": [
        "### Student Information\n",
        "- **Name:**\n",
        "- **Date:**\n",
        "- **Dataset Chosen:** (A or B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FessE6wssPXI"
      },
      "source": [
        "---\n",
        "## Setup\n",
        "\n",
        "<div style=\"background-color: #D5F5E3; border-left: 5px solid #27AE60; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1E8449;\">‚úÖ DO THIS</strong><br>\n",
        "  Run this cell. Do not modify.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bPlSYkJsPXJ"
      },
      "source": [
        "# ============================================================\n",
        "# Setup ‚Äî Run this cell. Do not modify.\n",
        "# ============================================================\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from scipy.stats import chi2_contingency, mannwhitneyu\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                             ConfusionMatrixDisplay, roc_curve, roc_auc_score,\n",
        "                             accuracy_score, precision_score, recall_score, f1_score)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
        "plt.rcParams[\"figure.dpi\"] = 100\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Helper functions (pre-built ‚Äî use these in your EDA)\n",
        "def cramers_v(x, y):\n",
        "    \"\"\"Cram√©r's V: association between two categorical variables (0‚Äì1).\"\"\"\n",
        "    ct = pd.crosstab(x, y)\n",
        "    chi2 = chi2_contingency(ct)[0]\n",
        "    n = ct.sum().sum()\n",
        "    r, k = ct.shape\n",
        "    return np.sqrt(chi2 / (n * (min(r, k) - 1)))\n",
        "\n",
        "def cohens_d(group1, group2):\n",
        "    \"\"\"Cohen's d: effect size between two groups.\"\"\"\n",
        "    n1, n2 = len(group1), len(group2)\n",
        "    pooled = np.sqrt(((n1-1)*group1.std()**2 + (n2-1)*group2.std()**2) / (n1+n2-2))\n",
        "    return (group1.mean() - group2.mean()) / pooled if pooled > 0 else 0\n",
        "\n",
        "print(f\"TensorFlow: {tf.__version__}\")\n",
        "print(\"‚úÖ Setup complete ‚Äî helper functions loaded: cramers_v(), cohens_d()\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6HZ7pTjsPXJ"
      },
      "source": [
        "---\n",
        "## Choose Your Dataset + Run Preprocessing\n",
        "\n",
        "<div style=\"background-color: #D5F5E3; border-left: 5px solid #27AE60; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1E8449;\">‚úÖ DO THIS</strong><br>\n",
        "  Uncomment <strong>ONE</strong> option below and run the cell. This handles all preprocessing and gives you clean train/test splits.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEXKyxKWsPXJ"
      },
      "source": [
        "# ============================================================\n",
        "# OPTION A ‚Äî Bank Customer Churn (~10,000 rows)\n",
        "# Uncomment the lines below if choosing Option A\n",
        "# ============================================================\n",
        "url = \"https://raw.githubusercontent.com/c-marq/cap4767-data-mining/refs/heads/main/data/Churn_Modelling.csv\"\n",
        "df_raw = pd.read_csv(url)\n",
        "TARGET = \"Exited\"\n",
        "DOMAIN = \"Banking\"\n",
        "\n",
        "# Preprocessing\n",
        "df = df_raw.drop(columns=[\"RowNumber\", \"CustomerId\", \"Surname\"])\n",
        "df[\"Gender\"] = df[\"Gender\"].map({\"Male\": 1, \"Female\": 0})\n",
        "df = pd.get_dummies(df, columns=[\"Geography\"], drop_first=True, dtype=int)\n",
        "\n",
        "# Feature lists for EDA\n",
        "cat_features = [\"Gender\", \"HasCrCard\", \"IsActiveMember\", \"NumOfProducts\",\n",
        "                \"Geography_Germany\", \"Geography_Spain\"]\n",
        "num_features = [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"EstimatedSalary\"]\n",
        "\n",
        "# ============================================================\n",
        "# OPTION B ‚Äî Credit Card Customer Attrition (~10,000 rows)\n",
        "# Uncomment the lines below if choosing Option B\n",
        "# ============================================================\n",
        "# url = \"https://raw.githubusercontent.com/c-marq/cap4767-data-mining/refs/heads/main/data/BankChurners.csv\"\n",
        "# df_raw = pd.read_csv(url)\n",
        "# TARGET = \"Attrition_Flag\"\n",
        "# DOMAIN = \"Credit Card Services\"\n",
        "#\n",
        "# # Preprocessing\n",
        "# # Drop ID and the two Naive Bayes leakage columns\n",
        "# leak_cols = [c for c in df_raw.columns if c.startswith(\"Naive_Bayes\")]\n",
        "# df = df_raw.drop(columns=[\"CLIENTNUM\"] + leak_cols)\n",
        "#\n",
        "# # Encode target: Attrited Customer = 1, Existing Customer = 0\n",
        "# df[TARGET] = df[TARGET].map({\"Attrited Customer\": 1, \"Existing Customer\": 0})\n",
        "#\n",
        "# # Encode categoricals\n",
        "# df[\"Gender\"] = df[\"Gender\"].map({\"M\": 1, \"F\": 0})\n",
        "# df = pd.get_dummies(df, columns=[\"Education_Level\", \"Marital_Status\",\n",
        "#                                    \"Income_Category\", \"Card_Category\"],\n",
        "#                      drop_first=True, dtype=int)\n",
        "#\n",
        "# # Feature lists for EDA\n",
        "# cat_features = [\"Gender\"] + [c for c in df.columns if any(\n",
        "#     c.startswith(p) for p in [\"Education_Level_\", \"Marital_Status_\",\n",
        "#                                \"Income_Category_\", \"Card_Category_\"])]\n",
        "# num_features = [\"Customer_Age\", \"Dependent_count\", \"Months_on_book\",\n",
        "#                 \"Total_Relationship_Count\", \"Months_Inactive_12_mon\",\n",
        "#                 \"Contacts_Count_12_mon\", \"Credit_Limit\", \"Total_Revolving_Bal\",\n",
        "#                 \"Avg_Open_To_Buy\", \"Total_Amt_Chng_Q4_Q1\", \"Total_Trans_Amt\",\n",
        "#                 \"Total_Trans_Ct\", \"Total_Ct_Chng_Q4_Q1\", \"Avg_Utilization_Ratio\"]\n",
        "\n",
        "# ============================================================\n",
        "# Common pipeline (runs for whichever option you chose)\n",
        "# ============================================================\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "feature_names = X_train.columns.tolist()\n",
        "n_features = len(feature_names)\n",
        "\n",
        "print(f\"Dataset: {DOMAIN}\")\n",
        "print(f\"Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns ‚Üí {n_features} features\")\n",
        "print(f\"Train: {X_train.shape[0]:,} | Test: {X_test.shape[0]:,}\")\n",
        "print(f\"Churn rate: {y.mean():.1%}\")\n",
        "print(f\"\\n‚úÖ Preprocessing complete ‚Äî X_train_scaled, X_test_scaled, y_train, y_test ready\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKn57WjqsPXK"
      },
      "source": [
        "<div style=\"background-color: #D6EAF8; border-left: 5px solid #2E86C1; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1A5276;\">üí° WHAT THE PREPROCESSING DID</strong><br>\n",
        "  <ul>\n",
        "    <li>Dropped non-predictive ID columns</li>\n",
        "    <li>Encoded the target as binary (1 = churned, 0 = stayed)</li>\n",
        "    <li>Converted categorical features to dummy variables with <code>drop_first=True</code></li>\n",
        "    <li>Scaled all features with <code>StandardScaler</code> (fit on train, transform on test)</li>\n",
        "    <li><strong>Option B only:</strong> Removed two columns that contained pre-computed model outputs ‚Äî using them would be <strong>data leakage</strong> (the model would \"cheat\" by seeing answers derived from the target)</li>\n",
        "  </ul>\n",
        "  <code>cat_features</code> and <code>num_features</code> lists are ready for your EDA.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-DkLe8fsPXK"
      },
      "source": [
        "---\n",
        "# Part A ‚Äî Exploratory Data Analysis (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byBA-GHYsPXK"
      },
      "source": [
        "### Task 1 ‚Äî Data Inspection (1 pt)\n",
        "\n",
        "<div style=\"background-color: #D5F5E3; border-left: 5px solid #27AE60; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1E8449;\">‚úÖ DO THIS</strong><br>\n",
        "  Print the shape, <code>.info()</code>, churn rate, and first 5 rows. Describe the dataset in 2‚Äì3 sentences.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc-IVLyWsPXK"
      },
      "source": [
        "# Task 1: Data inspection\n",
        "# YOUR CODE HERE\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdfA0vPdsPXL"
      },
      "source": [
        "**Dataset description (2‚Äì3 sentences):**\n",
        "\n",
        "*(Write here)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW_iR6J4sPXL"
      },
      "source": [
        "### Task 2 ‚Äî Cram√©r's V Analysis (1 pt)\n",
        "\n",
        "<div style=\"background-color: #D5F5E3; border-left: 5px solid #27AE60; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1E8449;\">‚úÖ DO THIS</strong><br>\n",
        "  Compute Cram√©r's V between each feature in <code>cat_features</code> and the target. Display as a sorted bar chart.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxuFinmIsPXL"
      },
      "source": [
        "# Task 2: Cram√©r's V\n",
        "# Hint: use the pre-built cramers_v() function and cat_features list\n",
        "# YOUR CODE HERE\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjGKU9u8sPXL"
      },
      "source": [
        "**Interpretation (2‚Äì3 sentences):** Which categorical features have the strongest association with churn?\n",
        "\n",
        "*(Write here)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQxAE344sPXL"
      },
      "source": [
        "### Task 3 ‚Äî Mann-Whitney U + Cohen's d (1 pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhA6wjiDsPXM"
      },
      "source": [
        "# Task 3: Mann-Whitney U + Cohen's d\n",
        "# Hint: use the pre-built cohens_d() function and num_features list\n",
        "# Split data: churned = df[df[TARGET]==1], stayed = df[df[TARGET]==0]\n",
        "# YOUR CODE HERE\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CoTlKtQsPXM"
      },
      "source": [
        "**Interpretation (2‚Äì3 sentences):** Which numerical features show the largest effect sizes?\n",
        "\n",
        "*(Write here)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPP6qo3vsPXM"
      },
      "source": [
        "### Task 4 ‚Äî Business Cost Estimate (1 pt)\n",
        "\n",
        "<div style=\"background-color: #D5F5E3; border-left: 5px solid #27AE60; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1E8449;\">‚úÖ DO THIS</strong><br>\n",
        "  Estimate the annual cost of churn. State your assumptions clearly in comments.<br>\n",
        "  Use reasonable estimates for your domain (banking or credit card services).\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylFzM52tsPXM"
      },
      "source": [
        "# Task 4: Business cost estimate\n",
        "# State your assumptions in comments\n",
        "# YOUR CODE HERE\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8APTXj5sPXM"
      },
      "source": [
        "---\n",
        "# Part B ‚Äî Logistic Regression (3 points)\n",
        "\n",
        "### Task 5 ‚Äî Build and Evaluate (1.5 pts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC_MxmLdsPXM"
      },
      "source": [
        "# Task 5: Logistic regression\n",
        "# Use X_train_scaled, X_test_scaled, y_train, y_test\n",
        "# Store: lr_predictions, lr_probabilities\n",
        "# Print classification report + AUC\n",
        "# YOUR CODE HERE\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5-hZAinsPXM"
      },
      "source": [
        "### Task 6 ‚Äî Coefficient Interpretation (1.5 pts)\n",
        "\n",
        "<div style=\"background-color: #D5F5E3; border-left: 5px solid #27AE60; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1E8449;\">‚úÖ DO THIS</strong><br>\n",
        "  Display top 5 positive and top 5 negative coefficients. Explain the top 3 churn drivers in business terms.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Th5WJCTsPXM"
      },
      "source": [
        "# Task 6: Coefficient interpretation\n",
        "# YOUR CODE HERE\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik4ipCo6sPXM"
      },
      "source": [
        "**Interpretation (3‚Äì4 sentences):** What does the model say drives churn in this business? Would these findings surprise company leadership?\n",
        "\n",
        "*(Write here)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrssfeYGsPXN"
      },
      "source": [
        "<div style=\"background-color: #FADBD8; border-left: 5px solid #E74C3C; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #922B21;\">üõë CHECKPOINT</strong><br>\n",
        "  LR should show reasonable accuracy (70‚Äì85%) and an AUC above 0.70. If accuracy equals the majority class rate exactly, the model may be predicting all one class.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTiPBq0hsPXN"
      },
      "source": [
        "---\n",
        "# Part C ‚Äî Neural Network (4 points)\n",
        "\n",
        "### Task 7 ‚Äî Build and Train a Keras ANN (2 pts)\n",
        "\n",
        "<div style=\"background-color: #D5F5E3; border-left: 5px solid #27AE60; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1E8449;\">‚úÖ DO THIS</strong><br>\n",
        "  Build a Sequential model with at least 2 hidden layers, dropout, and early stopping. Train and capture history.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vXo0iIDsPXN"
      },
      "source": [
        "# Task 7: Build and train ANN\n",
        "# YOUR CODE HERE\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz94vkYwsPXN"
      },
      "source": [
        "### Task 8 ‚Äî Training Curves (1 pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3oqVQLgsPXN"
      },
      "source": [
        "# Task 8: Plot training vs validation loss and accuracy\n",
        "# YOUR CODE HERE\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ejhXZ1zsPXN"
      },
      "source": [
        "**Interpretation (2‚Äì3 sentences):** What epoch did early stopping trigger? Is there evidence of overfitting?\n",
        "\n",
        "*(Write here)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHTNrwwgsPXN"
      },
      "source": [
        "### Task 9 ‚Äî Evaluate the ANN (1 pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CVYJkuhsPXN"
      },
      "source": [
        "# Task 9: Generate predictions + probabilities, print classification report\n",
        "# Store: ann_predictions, ann_probabilities\n",
        "# YOUR CODE HERE\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOa6PNXYsPXN"
      },
      "source": [
        "---\n",
        "# Part D ‚Äî Model Comparison (3 points)\n",
        "\n",
        "### Task 10 ‚Äî ROC + Metrics Table (3 pts)\n",
        "\n",
        "<div style=\"background-color: #D5F5E3; border-left: 5px solid #27AE60; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1E8449;\">‚úÖ DO THIS</strong><br>\n",
        "  <ol>\n",
        "    <li>Plot ROC curves for both models on a single figure (LR = navy, ANN = coral)</li>\n",
        "    <li>Build a comparison table: accuracy, precision, recall, F1, AUC for both</li>\n",
        "    <li>Count customers flagged by ANN but missed by LR</li>\n",
        "  </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbp0RZwfsPXO"
      },
      "source": [
        "# Task 10: ROC curves + comparison table + additional catches\n",
        "# YOUR CODE HERE\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M891I9bjsPXO"
      },
      "source": [
        "---\n",
        "# Part E ‚Äî Written Analysis (4 points)\n",
        "\n",
        "### Task 11 ‚Äî Model Recommendation (minimum 300 words)\n",
        "\n",
        "Write a recommendation addressed to the business leadership of your chosen domain. Address ALL five points:\n",
        "\n",
        "1. Which model should they deploy for their retention campaign, and why?\n",
        "2. What are the top 3 features driving churn, and what can the business do about each one?\n",
        "3. How many high-risk customers did your models identify? What's the estimated value of retaining them?\n",
        "4. What are the tradeoffs between the two models (accuracy vs interpretability)?\n",
        "5. Is there a scenario where deploying both models makes sense?\n",
        "\n",
        "*(Write here)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw53Rk8qsPXO"
      },
      "source": [
        "---\n",
        "# Bonus Challenge (+3 points)\n",
        "\n",
        "<div style=\"background-color: #D6EAF8; border-left: 5px solid #2E86C1; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1A5276;\">üí° OPTIONAL</strong><br>\n",
        "  Train a <strong>third model</strong> with a meaningfully different architecture. Change at least TWO of: number of layers, neurons per layer, dropout rate, optimizer. Add it to your ROC plot and comparison table.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j9s_m_xsPXO"
      },
      "source": [
        "# Bonus: Third model variant\n",
        "# YOUR CODE HERE\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RNug3WDsPXO"
      },
      "source": [
        "**Bonus interpretation (3‚Äì4 sentences):**\n",
        "\n",
        "*(Write here if attempting bonus)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58w-faJisPXO"
      },
      "source": [
        "---\n",
        "## Troubleshooting\n",
        "\n",
        "| Problem | Fix |\n",
        "|---------|-----|\n",
        "| ANN predicts all one class (accuracy = churn rate) | Check architecture ‚Äî may need more neurons or different learning rate |\n",
        "| `ValueError: shapes not aligned` | Verify `input_shape=(n_features,)` matches your feature count |\n",
        "| Option B accuracy is suspiciously high (>95%) | Check that Naive Bayes columns were dropped |\n",
        "| ROC curve is a straight line | Using predictions (0/1) instead of probabilities |\n",
        "| Training runs all 200 epochs | EarlyStopping not in callbacks list |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqE8G2JrsPXO"
      },
      "source": [
        "---\n",
        "<p style=\"color:#7F8C8D; font-size:0.85em;\">\n",
        "<em>CAP4767 Data Mining with Python | Miami Dade College | Spring 2026</em><br>\n",
        "Lab 3 ‚Äî Churn Prediction: Full Pipeline | 20 Points (+3 Bonus)\n",
        "</p>"
      ]
    }
  ]
}
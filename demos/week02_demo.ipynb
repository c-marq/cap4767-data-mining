{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-marq/cap4767-data-mining/blob/main/demos/week02_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEgblWU1DZhg"
      },
      "source": [
        "# Week 2 Demo ‚Äî Time Series Forecasting: SARIMAX + Prophet\n",
        "**CAP4767 Data Mining with Python** | Miami Dade College ‚Äî Kendall Campus\n",
        "\n",
        "---\n",
        "\n",
        "**What we're building today:** A complete end-to-end forecasting pipeline using two industry-standard models ‚Äî SARIMAX (classical statistics) and Prophet (Facebook/Meta's modern approach) ‚Äî then comparing them head-to-head.\n",
        "\n",
        "**Why this matters for data mining:** Forecasting is how businesses turn historical patterns into forward-looking decisions. Hotels predict occupancy to set room prices. Retailers forecast demand to manage inventory. Public health agencies forecast disease spread to allocate resources. The techniques you learn today are the same ones powering those systems.\n",
        "\n",
        "**Dataset:** Australian Tourism ‚Äî quarterly international holiday trips (1998‚Äì2016, 76 quarters). We use this as a \"comparable tourism economy\" exercise ‚Äî the seasonal patterns mirror what we see in South Florida.\n",
        "\n",
        "**Key concept:** We're comparing two fundamentally different philosophies:\n",
        "- **SARIMAX:** \"Model the math of the pattern\" ‚Äî explicitly defines trend, seasonality, and autocorrelation with parameters (p,d,q)(P,D,Q,s)\n",
        "- **Prophet:** \"Fit a flexible curve\" ‚Äî decomposes time series into trend + seasonality + holidays using an additive model\n",
        "\n",
        "**Adapted from:** Adhwaith Shankara Narayanan, *End to End Time Series Forecasting with SARIMAX and Prophet*"
      ],
      "id": "tEgblWU1DZhg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HwJoMPsDZhh"
      },
      "source": [
        "<div style=\"background-color: #D6EAF8; border-left: 5px solid #2E86C1; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #1A5276;\">üí° WHY ARE WE DOING THIS?</strong><br>\n",
        "<strong>Where does this fit in the data mining pipeline?</strong><br><br>Week 1 gave us the toolkit ‚Äî resampling, rolling windows, datetime indexing. Today we plug those skills into actual predictive models. This completes <strong>Competency 3</strong> (Forecasting) entirely. The temporal thinking you build here also feeds into Week 4 (churn prediction uses time-based features) and Week 7 (RFM recency is a time-series concept).\n",
        "</div>"
      ],
      "id": "9HwJoMPsDZhh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIFiNlEnDZhi"
      },
      "source": [
        "<div style=\"background-color: #D5F5E3; border-left: 5px solid #27AE60; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #1E8449;\">‚úÖ DO THIS</strong><br>\n",
        "Run the next two cells to install dependencies and load libraries. <strong>Do not modify.</strong><br><br>The first cell installs <code>pmdarima</code> (for auto_arima) and <code>prophet</code>. This takes about 30‚Äì60 seconds in Colab.\n",
        "</div>"
      ],
      "id": "pIFiNlEnDZhi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGIaFWHMDZhi"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Install dependencies ‚Äî Run this cell. Do not modify.\n",
        "# ============================================================\n",
        "!pip install -q pmdarima prophet\n",
        "\n",
        "print(\"‚úÖ pmdarima and prophet installed successfully.\")"
      ],
      "id": "XGIaFWHMDZhi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tg6DuYODZhj"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Imports ‚Äî Run this cell. Do not modify.\n",
        "# ============================================================\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from pmdarima import auto_arima\n",
        "from prophet import Prophet\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "# Suppress verbose Prophet/cmdstanpy output\n",
        "logging.getLogger(\"cmdstanpy\").setLevel(logging.WARNING)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"‚úÖ Libraries loaded successfully.\")"
      ],
      "id": "1tg6DuYODZhj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PRvTTZGDZhk"
      },
      "source": [
        "---\n",
        "## Section 1: Data Loading & Preprocessing"
      ],
      "id": "_PRvTTZGDZhk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBvzLY5jDZhk"
      },
      "source": [
        "<div style=\"background-color: #D6EAF8; border-left: 5px solid #2E86C1; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #1A5276;\">üí° WHY ARE WE DOING THIS?</strong><br>\n",
        "The raw tourism dataset has 23,000+ rows ‚Äî one per region, per quarter, per trip purpose. We need to filter for Holiday trips only, aggregate all regions into a national total, and set the quarterly datetime index. This is standard time-series preprocessing: go from granular transactional data to a single aggregated series.\n",
        "</div>"
      ],
      "id": "GBvzLY5jDZhk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGA-U5ymDZhl"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Load and preprocess ‚Äî Run this cell. Do not modify.\n",
        "# ============================================================\n",
        "tourism_url = \"https://raw.githubusercontent.com/c-marq/cap4767-data-mining/main/data/tourism.csv\"\n",
        "tourism_df = pd.read_csv(tourism_url, usecols=[\"Quarter\", \"Purpose\", \"Trips\"])\n",
        "\n",
        "print(f\"Raw dataset: {tourism_df.shape[0]:,} rows, {tourism_df.shape[1]} columns\")\n",
        "print(f\"Trip purposes: {tourism_df['Purpose'].unique().tolist()}\")\n",
        "print(f\"Quarter range: {tourism_df['Quarter'].min()} to {tourism_df['Quarter'].max()}\")\n",
        "tourism_df.head()"
      ],
      "id": "xGA-U5ymDZhl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S54jOZNPDZhl"
      },
      "outputs": [],
      "source": [
        "def preprocess_tourism_data(df):\n",
        "    \"\"\"\n",
        "    Filter for Holiday trips, aggregate to quarterly national totals,\n",
        "    and set datetime index with quarterly frequency.\n",
        "    \"\"\"\n",
        "    # Keep only Holiday trips\n",
        "    df = df[df[\"Purpose\"] == \"Holiday\"].copy()\n",
        "\n",
        "    # Convert quarter strings to datetime\n",
        "    df[\"Quarter\"] = pd.to_datetime(df[\"Quarter\"])\n",
        "\n",
        "    # Convert trips to integer (removes fractional survey artifacts)\n",
        "    df[\"Trips\"] = df[\"Trips\"].astype(np.int64)\n",
        "\n",
        "    # Sort by quarter\n",
        "    df.sort_values(\"Quarter\", inplace=True)\n",
        "\n",
        "    # Aggregate: sum all regional trips per quarter into one national number\n",
        "    aggregated = (\n",
        "        df.groupby(\"Quarter\")[\"Trips\"]\n",
        "        .sum()\n",
        "        .rename(\"Trips\")\n",
        "    )\n",
        "\n",
        "    # Set quarterly frequency so time-series methods work correctly\n",
        "    aggregated = aggregated.asfreq(\"QS\")\n",
        "\n",
        "    return aggregated\n",
        "\n",
        "# Run preprocessing\n",
        "ts_data = preprocess_tourism_data(tourism_df)\n",
        "print(f\"\\n‚úÖ Aggregated time series: {len(ts_data)} quarters\")\n",
        "print(f\"   Date range: {ts_data.index.min().strftime('%Y Q%q')} to {ts_data.index.max().strftime('%Y Q%q')}\")\n",
        "print(f\"   Mean quarterly trips: {ts_data.mean():,.0f}\")\n",
        "ts_data.head()"
      ],
      "id": "S54jOZNPDZhl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZK-_s-DDZhl"
      },
      "source": [
        "<div style=\"background-color: #FADBD8; border-left: 5px solid #E74C3C; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #922B21;\">üõë STOP AND CHECK</strong><br>\n",
        "<strong>Checkpoint ‚Äî Section 1</strong><br><br>You should see:<br>‚Ä¢ Raw dataset: 23,408 rows, 3 columns<br>‚Ä¢ Aggregated time series: <strong>76 quarters</strong> (1998 Q1 to 2016 Q4)<br>‚Ä¢ Mean quarterly trips: ~10,000‚Äì11,000<br>‚Ä¢ The index should be a <code>DatetimeIndex</code> with <code>freq='QS-JAN'</code>\n",
        "</div>"
      ],
      "id": "MZK-_s-DDZhl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QW7cXGdDZhm"
      },
      "source": [
        "---\n",
        "## Section 2: Exploratory Data Analysis"
      ],
      "id": "8QW7cXGdDZhm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4dtvYz7DZhm"
      },
      "source": [
        "<div style=\"background-color: #D6EAF8; border-left: 5px solid #2E86C1; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #1A5276;\">üí° WHY ARE WE DOING THIS?</strong><br>\n",
        "Before modeling, we need to answer three questions:<br><br>1. <strong>What does the series look like?</strong> ‚Äî Plot it, check for obvious trend and seasonality<br>2. <strong>Is it stationary?</strong> ‚Äî The ADF (Augmented Dickey-Fuller) test tells us. SARIMAX needs to know this to set the <code>d</code> parameter.<br>3. <strong>What are the components?</strong> ‚Äî Seasonal decomposition separates trend, seasonality, and residual noise.<br><br>This is the same workflow from Chapter 1, now applied with purpose ‚Äî each answer feeds directly into model configuration.\n",
        "</div>"
      ],
      "id": "l4dtvYz7DZhm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_fER6GrDZhm"
      },
      "source": [
        "### Time Series Plot"
      ],
      "id": "7_fER6GrDZhm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTwfKIYADZhm"
      },
      "outputs": [],
      "source": [
        "# Visualize the full series\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(ts_data.index, ts_data.values, color='steelblue', linewidth=1.5)\n",
        "plt.title(\"Australian Holiday Trips ‚Äî Quarterly (1998‚Äì2016)\", fontsize=14)\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Total Trips (thousands)\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Quick stats\n",
        "print(ts_data.describe().round(0))"
      ],
      "id": "UTwfKIYADZhm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDPaZruFDZhm"
      },
      "source": [
        "### Augmented Dickey-Fuller (ADF) Test for Stationarity"
      ],
      "id": "UDPaZruFDZhm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-QzmuZJDZhn"
      },
      "outputs": [],
      "source": [
        "# ADF Test: Is the series stationary?\n",
        "adf_result = adfuller(ts_data.dropna(), autolag=\"AIC\")\n",
        "\n",
        "print(\"Augmented Dickey-Fuller Test Results\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Test Statistic : {adf_result[0]:.4f}\")\n",
        "print(f\"P-value        : {adf_result[1]:.4f}\")\n",
        "print(f\"Lags Used      : {adf_result[2]}\")\n",
        "print(f\"Observations   : {adf_result[3]}\")\n",
        "print()\n",
        "\n",
        "if adf_result[1] < 0.05:\n",
        "    print(\"‚úÖ P-value < 0.05 ‚Üí Data IS stationary\")\n",
        "    print(\"   ‚Üí SARIMAX may use d=0 (no differencing needed)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  P-value >= 0.05 ‚Üí Data is NOT stationary\")\n",
        "    print(\"   ‚Üí SARIMAX will likely need d=1 (first differencing)\")"
      ],
      "id": "T-QzmuZJDZhn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuC6AF4ZDZhn"
      },
      "source": [
        "<div style=\"background-color: #FEF9E7; border-left: 5px solid #F1C40F; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #7D6608;\">‚ö†Ô∏è COMMON MISTAKE</strong><br>\n",
        "<strong>What does stationarity mean in plain English?</strong><br><br>A stationary series has a <em>consistent average</em> over time ‚Äî it doesn't trend up or down permanently. Think of ocean waves: the height varies, but the average sea level stays the same. If sea level is <em>rising</em> (like global warming), that's non-stationary.<br><br>SARIMAX needs stationary data to work properly. If the data isn't stationary, the <code>d</code> parameter tells it to <em>difference</em> the data first (subtract each value from the previous one) to remove the trend.\n",
        "</div>"
      ],
      "id": "UuC6AF4ZDZhn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7ehlIcfDZhn"
      },
      "source": [
        "### Seasonal Decomposition"
      ],
      "id": "q7ehlIcfDZhn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olvqMDjKDZhn"
      },
      "outputs": [],
      "source": [
        "# Decompose into Trend + Seasonal + Residual\n",
        "decomposition = seasonal_decompose(ts_data, model='additive')\n",
        "\n",
        "fig = decomposition.plot()\n",
        "fig.set_size_inches(12, 8)\n",
        "fig.suptitle(\"Seasonal Decomposition ‚Äî Australian Holiday Trips\", fontsize=14, y=1.01)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"What to look for:\")\n",
        "print(\"‚Ä¢ Trend panel:  Is there an overall upward or downward drift?\")\n",
        "print(\"‚Ä¢ Seasonal panel: Do the peaks repeat at the same interval? (Should be every 4 quarters)\")\n",
        "print(\"‚Ä¢ Residual panel: Is it random noise, or are there patterns the model isn't capturing?\")"
      ],
      "id": "olvqMDjKDZhn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9nGXHCkDZhn"
      },
      "source": [
        "<div style=\"background-color: #FADBD8; border-left: 5px solid #E74C3C; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #922B21;\">üõë STOP AND CHECK</strong><br>\n",
        "<strong>Checkpoint ‚Äî Section 2</strong><br><br>Your EDA should reveal:<br>‚Ä¢ <strong>Time series plot:</strong> Clear repeating peaks (Q1 = summer in Australia = peak holiday season) with a gradual upward trend<br>‚Ä¢ <strong>ADF test:</strong> The p-value will determine stationarity ‚Äî check whether it's above or below 0.05<br>‚Ä¢ <strong>Decomposition:</strong> The seasonal component should show a regular 4-quarter cycle. The trend should show gradual growth.\n",
        "</div>"
      ],
      "id": "c9nGXHCkDZhn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3kAMwTpDZhn"
      },
      "source": [
        "---\n",
        "## Section 3: Train/Test Split"
      ],
      "id": "t3kAMwTpDZhn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGLGlcIqDZho"
      },
      "source": [
        "<div style=\"background-color: #D6EAF8; border-left: 5px solid #2E86C1; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #1A5276;\">üí° WHY ARE WE DOING THIS?</strong><br>\n",
        "Time series splitting is <strong>different from regular ML</strong>. We can't randomly shuffle ‚Äî the order matters. We always train on the <em>past</em> and test on the <em>future</em>. This is called a <strong>temporal split</strong>.<br><br>We'll use the first 64 quarters for training (1998‚Äì2013) and the last 12 quarters for testing (2014‚Äì2016). This gives us 3 full years of out-of-sample data to evaluate our forecasts.\n",
        "</div>"
      ],
      "id": "iGLGlcIqDZho"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPH_VWtWDZho"
      },
      "outputs": [],
      "source": [
        "def train_test_split_ts(series, train_size):\n",
        "    \"\"\"\n",
        "    Temporal split ‚Äî train on the past, test on the future.\n",
        "    Never shuffle time series data!\n",
        "    \"\"\"\n",
        "    train = series.iloc[:train_size]\n",
        "    test = series.iloc[train_size:]\n",
        "    return train, test\n",
        "\n",
        "# Split: 64 quarters train / 12 quarters test\n",
        "train_data, test_data = train_test_split_ts(ts_data, train_size=64)\n",
        "\n",
        "print(f\"Train: {len(train_data)} quarters ({train_data.index.min().year}‚Äì{train_data.index.max().year})\")\n",
        "print(f\"Test:  {len(test_data)} quarters ({test_data.index.min().year}‚Äì{test_data.index.max().year})\")\n",
        "\n",
        "# Visualize the split\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(train_data.index, train_data, label=f\"Train ({len(train_data)} Q)\", color=\"steelblue\")\n",
        "plt.plot(test_data.index, test_data, label=f\"Test ({len(test_data)} Q)\", color=\"darkorange\")\n",
        "plt.axvline(x=test_data.index[0], color='red', linestyle='--', alpha=0.7, label='Split Point')\n",
        "plt.title(\"Temporal Train/Test Split\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Trips\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "QPH_VWtWDZho"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xr9SUeBDZho"
      },
      "source": [
        "<div style=\"background-color: #FEF9E7; border-left: 5px solid #F1C40F; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #7D6608;\">‚ö†Ô∏è COMMON MISTAKE</strong><br>\n",
        "<strong>Why 64/12 and not 80/20?</strong><br><br>With only 76 quarters, we want the test set to cover at least 3 full seasonal cycles (12 quarters = 3 years). This lets us evaluate whether the model captures seasonality ‚Äî not just the trend. If we only tested on 1 year, a model that gets the trend right but misses the seasonal peaks would look good by accident.\n",
        "</div>"
      ],
      "id": "4xr9SUeBDZho"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InsJV9nTDZho"
      },
      "source": [
        "---\n",
        "## Section 4: SARIMAX ‚Äî Parameter Selection with auto_arima"
      ],
      "id": "InsJV9nTDZho"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lghkkNWDZho"
      },
      "source": [
        "<div style=\"background-color: #D6EAF8; border-left: 5px solid #2E86C1; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #1A5276;\">üí° WHY ARE WE DOING THIS?</strong><br>\n",
        "SARIMAX has 7 parameters: <code>(p, d, q)(P, D, Q, s)</code>. Choosing them manually requires deep statistical expertise ‚Äî reading ACF/PACF plots, testing multiple combinations, checking AIC scores. That's a graduate-level skill.<br><br><code>auto_arima</code> from the <code>pmdarima</code> library automates this search. It tries thousands of parameter combinations and picks the one with the best AIC (Akaike Information Criterion ‚Äî a measure of model fit that penalizes complexity). Think of it as a smart search algorithm that does in 30 seconds what would take a statistician hours.\n",
        "</div>"
      ],
      "id": "7lghkkNWDZho"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNDL21MADZho"
      },
      "source": [
        "### What do the SARIMAX parameters mean?\n",
        "\n",
        "| Parameter | Name | What it controls |\n",
        "|-----------|------|------------------|\n",
        "| `p` | AR order | How many past values influence the current value |\n",
        "| `d` | Differencing | How many times to subtract consecutive values (removes trend) |\n",
        "| `q` | MA order | How many past forecast errors influence the current value |\n",
        "| `P` | Seasonal AR | Same as `p`, but for the seasonal pattern |\n",
        "| `D` | Seasonal differencing | Removes seasonal trend |\n",
        "| `Q` | Seasonal MA | Same as `q`, but for seasonal errors |\n",
        "| `s` | Seasonal period | Length of one seasonal cycle (4 for quarterly data) |"
      ],
      "id": "hNDL21MADZho"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGG2Hl4vDZhp"
      },
      "outputs": [],
      "source": [
        "def run_auto_arima(train_data, seasonal=True, m=4):\n",
        "    \"\"\"\n",
        "    Use auto_arima to find the best SARIMAX parameters.\n",
        "    m=4 because our data is quarterly (4 quarters = 1 seasonal cycle).\n",
        "    \"\"\"\n",
        "    model = auto_arima(\n",
        "        train_data,\n",
        "        seasonal=seasonal,\n",
        "        m=m,\n",
        "        suppress_warnings=True,\n",
        "        error_action=\"ignore\",\n",
        "        trace=False\n",
        "    )\n",
        "\n",
        "    order = model.order\n",
        "    seasonal_order = model.seasonal_order\n",
        "\n",
        "    params = {\n",
        "        \"p\": order[0], \"d\": order[1], \"q\": order[2],\n",
        "        \"P\": seasonal_order[0], \"D\": seasonal_order[1],\n",
        "        \"Q\": seasonal_order[2], \"s\": seasonal_order[3]\n",
        "    }\n",
        "    return model, params\n",
        "\n",
        "# Run auto_arima ‚Äî this takes ~15-30 seconds\n",
        "print(\"Running auto_arima parameter search...\")\n",
        "auto_model, sarimax_params = run_auto_arima(train_data, seasonal=True, m=4)\n",
        "\n",
        "print(f\"\\n‚úÖ Best SARIMAX parameters found:\")\n",
        "print(f\"   Order:          ({sarimax_params['p']}, {sarimax_params['d']}, {sarimax_params['q']})\")\n",
        "print(f\"   Seasonal Order: ({sarimax_params['P']}, {sarimax_params['D']}, {sarimax_params['Q']}, {sarimax_params['s']})\")\n",
        "print(f\"   AIC:            {auto_model.aic():.2f}\")\n",
        "print(f\"\\n{auto_model.summary()}\")"
      ],
      "id": "kGG2Hl4vDZhp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s9jnTSRDZhp"
      },
      "source": [
        "<div style=\"background-color: #FADBD8; border-left: 5px solid #E74C3C; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #922B21;\">üõë STOP AND CHECK</strong><br>\n",
        "<strong>Checkpoint ‚Äî Section 4</strong><br><br>auto_arima should finish in under 30 seconds and print a parameter summary. You should see values like <code>(p, d, q) = (0, 1, 1)</code> and <code>(P, D, Q, 4) = (0, 1, 1, 4)</code> ‚Äî though exact values may vary slightly. The <code>s=4</code> confirms it detected quarterly seasonality.<br><br>If you get a convergence warning, that's normal ‚Äî auto_arima tries many combinations and some don't converge.\n",
        "</div>"
      ],
      "id": "3s9jnTSRDZhp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkpPBPyADZhp"
      },
      "source": [
        "---\n",
        "## Section 5: SARIMAX ‚Äî Fit, Forecast, and Evaluate"
      ],
      "id": "fkpPBPyADZhp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-36SNGLDZhp"
      },
      "source": [
        "<div style=\"background-color: #D6EAF8; border-left: 5px solid #2E86C1; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #1A5276;\">üí° WHY ARE WE DOING THIS?</strong><br>\n",
        "Now we take the parameters auto_arima found and build the actual SARIMAX model. The workflow is: <strong>fit on training data ‚Üí forecast the test period ‚Üí compare forecast to actuals ‚Üí measure error</strong>. We use two metrics:<br><br>‚Ä¢ <strong>RMSE</strong> (Root Mean Squared Error) ‚Äî average forecast error in the same units as the data (trips). Lower is better.<br>‚Ä¢ <strong>R¬≤</strong> (R-squared) ‚Äî proportion of variance explained. 1.0 = perfect, 0.0 = no better than guessing the mean.\n",
        "</div>"
      ],
      "id": "8-36SNGLDZhp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DykwZmNEDZhp"
      },
      "outputs": [],
      "source": [
        "def sarimax_model(train, test=None, params=None, forecast_periods=None):\n",
        "    \"\"\"\n",
        "    Fit SARIMAX model and optionally evaluate against test data.\n",
        "    Returns forecast (and metrics if test data provided).\n",
        "    \"\"\"\n",
        "    model = SARIMAX(\n",
        "        train,\n",
        "        order=(params[\"p\"], params[\"d\"], params[\"q\"]),\n",
        "        seasonal_order=(params[\"P\"], params[\"D\"], params[\"Q\"], params[\"s\"]),\n",
        "        enforce_stationarity=False,\n",
        "        enforce_invertibility=False\n",
        "    )\n",
        "    result = model.fit(disp=False)\n",
        "\n",
        "    # Forecast length\n",
        "    steps = len(test) if test is not None else forecast_periods\n",
        "    forecast = result.forecast(steps=steps)\n",
        "\n",
        "    # Evaluate if test data provided\n",
        "    if test is not None:\n",
        "        rmse = np.sqrt(mean_squared_error(test, forecast))\n",
        "        r2 = r2_score(test, forecast)\n",
        "        return forecast, rmse, r2\n",
        "    else:\n",
        "        return forecast\n",
        "\n",
        "# Fit and evaluate on test set\n",
        "sarimax_forecast, sarimax_rmse, sarimax_r2 = sarimax_model(\n",
        "    train=train_data,\n",
        "    test=test_data,\n",
        "    params=sarimax_params\n",
        ")\n",
        "\n",
        "print(\"SARIMAX Test Set Performance\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"RMSE: {sarimax_rmse:,.0f} trips\")\n",
        "print(f\"R¬≤:   {sarimax_r2:.4f}\")"
      ],
      "id": "DykwZmNEDZhp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYvvcwl0DZhq"
      },
      "source": [
        "### Visualize: SARIMAX Forecast vs Actuals"
      ],
      "id": "fYvvcwl0DZhq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgWMPbtCDZhq"
      },
      "outputs": [],
      "source": [
        "def plot_forecast(train, test, forecast, title, future_forecast=None, future_index=None):\n",
        "    \"\"\"\n",
        "    Plot train, test actuals, test forecast, and optional future forecast.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(train.index, train, label=\"Train\", color=\"steelblue\")\n",
        "    plt.plot(test.index, test, label=\"Test (Actual)\", color=\"darkorange\", linewidth=2)\n",
        "    plt.plot(test.index, forecast, label=\"Forecast\", linestyle=\"--\", color=\"green\", linewidth=2)\n",
        "\n",
        "    if future_forecast is not None and future_index is not None:\n",
        "        plt.plot(future_index, future_forecast, label=\"Future Forecast\",\n",
        "                 linestyle=\"--\", color=\"red\", linewidth=2)\n",
        "\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.xlabel(\"Quarter\")\n",
        "    plt.ylabel(\"Trips\")\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot SARIMAX results\n",
        "plot_forecast(\n",
        "    train=train_data,\n",
        "    test=test_data,\n",
        "    forecast=sarimax_forecast,\n",
        "    title=f\"SARIMAX Forecast vs Actuals (RMSE={sarimax_rmse:,.0f}, R¬≤={sarimax_r2:.3f})\"\n",
        ")"
      ],
      "id": "xgWMPbtCDZhq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv78lWQ1DZhq"
      },
      "source": [
        "### SARIMAX Future Forecast (Beyond Known Data)"
      ],
      "id": "Sv78lWQ1DZhq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nkxQ7vvDZhq"
      },
      "outputs": [],
      "source": [
        "# Retrain on ALL data, then forecast 8 quarters into the unknown future\n",
        "full_data = pd.concat([train_data, test_data])\n",
        "future_periods = 8\n",
        "\n",
        "sarimax_future = sarimax_model(\n",
        "    train=full_data,\n",
        "    params=sarimax_params,\n",
        "    forecast_periods=future_periods\n",
        ")\n",
        "\n",
        "# Build future date index\n",
        "future_index = pd.date_range(\n",
        "    start=full_data.index[-1] + pd.tseries.frequencies.to_offset(\"QS\"),\n",
        "    periods=future_periods,\n",
        "    freq=\"QS\"\n",
        ")\n",
        "\n",
        "# Plot everything: train + test + future\n",
        "plot_forecast(\n",
        "    train=train_data,\n",
        "    test=test_data,\n",
        "    forecast=sarimax_forecast,\n",
        "    future_forecast=sarimax_future,\n",
        "    future_index=future_index,\n",
        "    title=\"SARIMAX ‚Äî Full Pipeline: Historical + Test + Future Forecast\"\n",
        ")\n",
        "\n",
        "print(\"\\nüìä SARIMAX Future Forecast (8 Quarters):\")\n",
        "print(pd.DataFrame({\"Quarter\": future_index, \"Predicted_Trips\": sarimax_future.round().astype(int).values}\n",
        "    ).to_string(index=False))"
      ],
      "id": "0nkxQ7vvDZhq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGHq4R_WDZhq"
      },
      "source": [
        "<div style=\"background-color: #FADBD8; border-left: 5px solid #E74C3C; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #922B21;\">üõë STOP AND CHECK</strong><br>\n",
        "<strong>Checkpoint ‚Äî Section 5</strong><br><br>You should see three outputs:<br>‚Ä¢ <strong>Metrics:</strong> RMSE and R¬≤ printed. R¬≤ should be positive (better than guessing the mean). If R¬≤ is negative, the model is performing <em>worse</em> than the baseline ‚Äî that's a sign something went wrong.<br>‚Ä¢ <strong>Forecast plot:</strong> The green dashed line (forecast) should roughly follow the orange line (actuals) during the test period.<br>‚Ä¢ <strong>Future forecast:</strong> The red dashed line extends 8 quarters beyond the known data. It should continue the seasonal pattern.\n",
        "</div>"
      ],
      "id": "cGHq4R_WDZhq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aTYF_RXDZhq"
      },
      "source": [
        "---\n",
        "## Section 6: Prophet ‚Äî Fit, Forecast, and Evaluate"
      ],
      "id": "7aTYF_RXDZhq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IdxX7oYDZhu"
      },
      "source": [
        "<div style=\"background-color: #D6EAF8; border-left: 5px solid #2E86C1; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #1A5276;\">üí° WHY ARE WE DOING THIS?</strong><br>\n",
        "Prophet takes a completely different approach than SARIMAX. Instead of modeling autocorrelation, it fits a <strong>decomposable model</strong>: <code>y(t) = trend(t) + seasonality(t) + holidays(t) + error(t)</code>.<br><br>Key differences:<br>‚Ä¢ Prophet doesn't require stationary data ‚Äî it handles trend internally<br>‚Ä¢ It uses a different input format: a DataFrame with columns <code>ds</code> (dates) and <code>y</code> (values)<br>‚Ä¢ Parameters control <em>flexibility</em> rather than lag structure ‚Äî how quickly can the trend change? How strong is the seasonality?<br><br>We'll use reasonable default parameters instead of a grid search. For quarterly tourism data, the defaults below work well.\n",
        "</div>"
      ],
      "id": "5IdxX7oYDZhu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyGAQ2KEDZhv"
      },
      "source": [
        "### Prophet Parameters (Direct Defaults)\n",
        "\n",
        "| Parameter | Value | What it controls |\n",
        "|-----------|-------|------------------|\n",
        "| `changepoint_prior_scale` | 0.05 | How flexible the trend is (higher = more wiggly) |\n",
        "| `seasonality_prior_scale` | 10.0 | Strength of seasonal component |\n",
        "| `holidays_prior_scale` | 0.1 | Influence of holidays (low ‚Äî our data is quarterly) |\n",
        "| `seasonality_mode` | `'multiplicative'` | Seasonal effect grows with the trend (vs additive) |\n",
        "| `changepoint_range` | 0.85 | How far into the training data changepoints are allowed |"
      ],
      "id": "uyGAQ2KEDZhv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOgpYaVLDZhv"
      },
      "outputs": [],
      "source": [
        "# Prophet parameters ‚Äî reasonable defaults for quarterly tourism data\n",
        "prophet_params = {\n",
        "    \"changepoint_prior_scale\": 0.05,\n",
        "    \"seasonality_prior_scale\": 10.0,\n",
        "    \"holidays_prior_scale\": 0.1,\n",
        "    \"seasonality_mode\": \"multiplicative\",\n",
        "    \"changepoint_range\": 0.85\n",
        "}\n",
        "\n",
        "def prophet_model(train, test=None, params=None, forecast_periods=None):\n",
        "    \"\"\"\n",
        "    Fit Prophet model and optionally evaluate against test data.\n",
        "    Prophet requires a DataFrame with columns 'ds' (date) and 'y' (value).\n",
        "    \"\"\"\n",
        "    train_df = pd.DataFrame({\"ds\": train.index, \"y\": train.values})\n",
        "\n",
        "    model = Prophet(\n",
        "        changepoint_prior_scale=params[\"changepoint_prior_scale\"],\n",
        "        seasonality_prior_scale=params[\"seasonality_prior_scale\"],\n",
        "        holidays_prior_scale=params[\"holidays_prior_scale\"],\n",
        "        seasonality_mode=params[\"seasonality_mode\"],\n",
        "        changepoint_range=params[\"changepoint_range\"],\n",
        "        yearly_seasonality=True,\n",
        "        weekly_seasonality=False,   # Not relevant for quarterly data\n",
        "        daily_seasonality=False     # Not relevant for quarterly data\n",
        "    )\n",
        "\n",
        "    model.fit(train_df)\n",
        "\n",
        "    # Determine forecast horizon\n",
        "    periods = len(test) if test is not None else forecast_periods\n",
        "\n",
        "    future = model.make_future_dataframe(periods=periods, freq=\"QS\")\n",
        "    forecast = model.predict(future)\n",
        "    yhat = forecast[\"yhat\"].iloc[-periods:].values\n",
        "\n",
        "    # Evaluate if test data provided\n",
        "    if test is not None:\n",
        "        rmse = np.sqrt(mean_squared_error(test.values, yhat))\n",
        "        r2 = r2_score(test.values, yhat)\n",
        "        return yhat, rmse, r2, model\n",
        "    else:\n",
        "        return yhat, model\n",
        "\n",
        "# Fit and evaluate on test set\n",
        "prophet_forecast, prophet_rmse, prophet_r2, fitted_prophet = prophet_model(\n",
        "    train=train_data,\n",
        "    test=test_data,\n",
        "    params=prophet_params\n",
        ")\n",
        "\n",
        "print(\"Prophet Test Set Performance\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"RMSE: {prophet_rmse:,.0f} trips\")\n",
        "print(f\"R¬≤:   {prophet_r2:.4f}\")"
      ],
      "id": "gOgpYaVLDZhv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06CCXSayDZhv"
      },
      "source": [
        "### Prophet's Built-In Component Plots"
      ],
      "id": "06CCXSayDZhv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEkSK_KPDZhv"
      },
      "outputs": [],
      "source": [
        "# Prophet has its own decomposition ‚Äî trend + yearly seasonality\n",
        "fig = fitted_prophet.plot_components(\n",
        "    fitted_prophet.predict(\n",
        "        fitted_prophet.make_future_dataframe(periods=len(test_data), freq=\"QS\")\n",
        "    )\n",
        ")\n",
        "plt.suptitle(\"Prophet Components ‚Äî Trend + Yearly Seasonality\", fontsize=14, y=1.01)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "YEkSK_KPDZhv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyzHgWH7DZhw"
      },
      "source": [
        "### Visualize: Prophet Forecast vs Actuals"
      ],
      "id": "OyzHgWH7DZhw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2QOHuWTDZhw"
      },
      "outputs": [],
      "source": [
        "# Plot Prophet results\n",
        "plot_forecast(\n",
        "    train=train_data,\n",
        "    test=test_data,\n",
        "    forecast=prophet_forecast,\n",
        "    title=f\"Prophet Forecast vs Actuals (RMSE={prophet_rmse:,.0f}, R¬≤={prophet_r2:.3f})\"\n",
        ")"
      ],
      "id": "a2QOHuWTDZhw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9DiUxz5DZhw"
      },
      "source": [
        "### Prophet Future Forecast"
      ],
      "id": "y9DiUxz5DZhw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phRC9C3XDZhw"
      },
      "outputs": [],
      "source": [
        "# Retrain Prophet on ALL data, forecast 8 quarters ahead\n",
        "prophet_future, _ = prophet_model(\n",
        "    train=full_data,\n",
        "    params=prophet_params,\n",
        "    forecast_periods=future_periods\n",
        ")\n",
        "\n",
        "# Plot everything\n",
        "plot_forecast(\n",
        "    train=train_data,\n",
        "    test=test_data,\n",
        "    forecast=prophet_forecast,\n",
        "    future_forecast=prophet_future,\n",
        "    future_index=future_index,\n",
        "    title=\"Prophet ‚Äî Full Pipeline: Historical + Test + Future Forecast\"\n",
        ")\n",
        "\n",
        "print(\"\\nüìä Prophet Future Forecast (8 Quarters):\")\n",
        "print(pd.DataFrame({\"Quarter\": future_index, \"Predicted_Trips\": np.round(prophet_future).astype(int)\n",
        "    }).to_string(index=False))"
      ],
      "id": "phRC9C3XDZhw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZelNZ_YDZhw"
      },
      "source": [
        "<div style=\"background-color: #FADBD8; border-left: 5px solid #E74C3C; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #922B21;\">üõë STOP AND CHECK</strong><br>\n",
        "<strong>Checkpoint ‚Äî Section 6</strong><br><br>You should see Prophet's metrics, component plots, and forecast visualization. Compare mentally to SARIMAX:<br>‚Ä¢ Which model has the lower RMSE?<br>‚Ä¢ Which forecast line tracks the orange actuals more closely?<br>‚Ä¢ Do the future forecasts look reasonable, or does either model produce something unrealistic?\n",
        "</div>"
      ],
      "id": "8ZelNZ_YDZhw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng3PlavlDZhx"
      },
      "source": [
        "---\n",
        "## Section 7: Head-to-Head Comparison"
      ],
      "id": "ng3PlavlDZhx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uro8sSBLDZhx"
      },
      "source": [
        "<div style=\"background-color: #D6EAF8; border-left: 5px solid #2E86C1; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #1A5276;\">üí° WHY ARE WE DOING THIS?</strong><br>\n",
        "This is the payoff. We've run two completely different models on the same data with the same train/test split. Now we compare them side by side ‚Äî not just on metrics, but visually. In a real business setting, you'd present this comparison table to stakeholders and recommend one model with justification.\n",
        "</div>"
      ],
      "id": "uro8sSBLDZhx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQHgYKAbDZhx"
      },
      "outputs": [],
      "source": [
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# Side-by-side comparison table\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "comparison = pd.DataFrame({\n",
        "    \"Metric\": [\"RMSE (trips)\", \"R¬≤\", \"Approach\", \"Parameters\", \"Handles Trend\", \"Requires Stationarity\"],\n",
        "    \"SARIMAX\": [\n",
        "        f\"{sarimax_rmse:,.0f}\",\n",
        "        f\"{sarimax_r2:.4f}\",\n",
        "        \"Statistical (ARIMA family)\",\n",
        "        f\"({sarimax_params['p']},{sarimax_params['d']},{sarimax_params['q']})({sarimax_params['P']},{sarimax_params['D']},{sarimax_params['Q']},{sarimax_params['s']})\",\n",
        "        \"Via differencing (d, D)\",\n",
        "        \"Yes\"\n",
        "    ],\n",
        "    \"Prophet\": [\n",
        "        f\"{prophet_rmse:,.0f}\",\n",
        "        f\"{prophet_r2:.4f}\",\n",
        "        \"Decomposable (trend + season)\",\n",
        "        \"changepoint + seasonality priors\",\n",
        "        \"Built-in trend component\",\n",
        "        \"No\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\")\n",
        "print(\"‚ïë     SARIMAX  vs  Prophet ‚Äî Comparison        ‚ïë\")\n",
        "print(\"‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\\n\")\n",
        "print(comparison.to_string(index=False))\n",
        "\n",
        "# Determine winner\n",
        "if sarimax_rmse < prophet_rmse:\n",
        "    print(f\"\\nüèÜ SARIMAX wins on RMSE by {prophet_rmse - sarimax_rmse:,.0f} trips\")\n",
        "else:\n",
        "    print(f\"\\nüèÜ Prophet wins on RMSE by {sarimax_rmse - prophet_rmse:,.0f} trips\")"
      ],
      "id": "qQHgYKAbDZhx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCFHOYA4DZhx"
      },
      "source": [
        "### Combined Forecast Plot"
      ],
      "id": "TCFHOYA4DZhx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7J2RKDNDZhy"
      },
      "outputs": [],
      "source": [
        "# Both forecasts on one chart for direct visual comparison\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(train_data.index, train_data, label=\"Train\", color=\"steelblue\", alpha=0.7)\n",
        "plt.plot(test_data.index, test_data, label=\"Test (Actual)\", color=\"darkorange\", linewidth=2.5)\n",
        "plt.plot(test_data.index, sarimax_forecast, label=f\"SARIMAX (RMSE={sarimax_rmse:,.0f})\",\n",
        "         linestyle=\"--\", color=\"green\", linewidth=2)\n",
        "plt.plot(test_data.index, prophet_forecast, label=f\"Prophet (RMSE={prophet_rmse:,.0f})\",\n",
        "         linestyle=\"--\", color=\"purple\", linewidth=2)\n",
        "\n",
        "# Future forecasts\n",
        "plt.plot(future_index, sarimax_future, linestyle=\":\", color=\"green\", alpha=0.6, label=\"SARIMAX Future\")\n",
        "plt.plot(future_index, prophet_future, linestyle=\":\", color=\"purple\", alpha=0.6, label=\"Prophet Future\")\n",
        "\n",
        "plt.axvline(x=test_data.index[0], color='red', linestyle='--', alpha=0.4)\n",
        "plt.title(\"SARIMAX vs Prophet ‚Äî Combined Forecast Comparison\", fontsize=14)\n",
        "plt.xlabel(\"Quarter\")\n",
        "plt.ylabel(\"Trips\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "_7J2RKDNDZhy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7NibIJgDZhy"
      },
      "source": [
        "### Residual Analysis: Where Did Each Model Struggle?"
      ],
      "id": "u7NibIJgDZhy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il8IDTKUDZhy"
      },
      "outputs": [],
      "source": [
        "# Residuals = Actual - Predicted (positive = underforecast, negative = overforecast)\n",
        "residuals = pd.DataFrame({\n",
        "    \"Quarter\": test_data.index,\n",
        "    \"Actual\": test_data.values,\n",
        "    \"SARIMAX_Forecast\": sarimax_forecast.values,\n",
        "    \"Prophet_Forecast\": prophet_forecast,\n",
        "    \"SARIMAX_Error\": test_data.values - sarimax_forecast.values,\n",
        "    \"Prophet_Error\": test_data.values - prophet_forecast\n",
        "})\n",
        "\n",
        "print(\"Residual Analysis ‚Äî Test Period\")\n",
        "print(\"=\" * 60)\n",
        "print(residuals.to_string(index=False))\n",
        "\n",
        "# Which quarters had the largest errors?\n",
        "print(f\"\\nSARIMAX max error: Q{residuals.loc[residuals['SARIMAX_Error'].abs().idxmax(), 'Quarter'].quarter} \"\n",
        "      f\"{residuals.loc[residuals['SARIMAX_Error'].abs().idxmax(), 'Quarter'].year} \"\n",
        "      f\"({residuals['SARIMAX_Error'].abs().max():,.0f} trips)\")\n",
        "print(f\"Prophet max error: Q{residuals.loc[residuals['Prophet_Error'].abs().idxmax(), 'Quarter'].quarter} \"\n",
        "      f\"{residuals.loc[residuals['Prophet_Error'].abs().idxmax(), 'Quarter'].year} \"\n",
        "      f\"({residuals['Prophet_Error'].abs().max():,.0f} trips)\")"
      ],
      "id": "Il8IDTKUDZhy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9PWWfoMDZhy"
      },
      "source": [
        "<div style=\"background-color: #FADBD8; border-left: 5px solid #E74C3C; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "<strong style=\"color: #922B21;\">üõë STOP AND CHECK</strong><br>\n",
        "<strong>Checkpoint ‚Äî Section 7</strong><br><br>You should have:<br>‚Ä¢ A comparison table with RMSE and R¬≤ for both models<br>‚Ä¢ A combined forecast plot showing both models' predictions overlaid on actuals<br>‚Ä¢ A residual table showing where each model was most wrong<br><br>There is no universally \"better\" model ‚Äî the winner depends on the data. That's the whole point of comparing.\n",
        "</div>"
      ],
      "id": "D9PWWfoMDZhy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUNMa8yIDZhy"
      },
      "source": [
        "---\n",
        "## Wrap-Up: What We Learned & What's Next\n",
        "\n",
        "**Today's complete forecasting pipeline:**\n",
        "\n",
        "| Step | What We Did | Key Function |\n",
        "|------|------------|--------------|\n",
        "| 1. Preprocess | Filter, aggregate, set datetime index | `preprocess_tourism_data()` |\n",
        "| 2. EDA | Time plot, ADF stationarity test, seasonal decomposition | `adfuller()`, `seasonal_decompose()` |\n",
        "| 3. Split | Temporal train/test (64/12 quarters) | `train_test_split_ts()` |\n",
        "| 4. SARIMAX | auto_arima parameter search ‚Üí fit ‚Üí forecast ‚Üí evaluate | `auto_arima()`, `SARIMAX()` |\n",
        "| 5. Prophet | Direct params ‚Üí fit ‚Üí forecast ‚Üí evaluate | `Prophet()` |\n",
        "| 6. Compare | RMSE, R¬≤, combined plots, residual analysis | Side-by-side table |\n",
        "\n",
        "**Key takeaways:**\n",
        "- SARIMAX requires stationary data and explicit parameter tuning ‚Äî but gives interpretable coefficients\n",
        "- Prophet handles trend and seasonality automatically ‚Äî but is a \"black box\" by comparison\n",
        "- **Always compare multiple models** ‚Äî the best approach depends on the specific dataset\n",
        "\n",
        "**Next week (Week 3):** Regression ‚Äî we move from forecasting *future values of the same variable* to predicting *one variable from others*. Linear ‚Üí Multiple ‚Üí Logistic regression builds the supervised learning foundation for Week 4's neural networks.\n",
        "\n",
        "---\n",
        "*CAP4767 Data Mining with Python | Miami Dade College | Spring 2026*"
      ],
      "id": "rUNMa8yIDZhy"
    }
  ]
}
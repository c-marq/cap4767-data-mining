{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-marq/cap4767-data-mining/blob/main/solutions/exercises/week05_group_exercise_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp3nr6Ib_8N1"
      },
      "source": [
        "# Week 5 Group Exercise ‚Äî SOLUTION KEY üîë ‚Äî RFM + K-Means on a New Dataset\n",
        "**CAP4767 Data Mining with Python** | Miami Dade College ‚Äî Kendall Campus\n",
        "\n",
        "**Points:** 10 | **Duration:** ~45 minutes | **Deliverable:** Completed notebook + 3-minute presentation\n",
        "\n",
        "**Objective:** Run the complete RFM + K-Means pipeline on a **different dataset** from the demo. Apply what you learned in both sessions ‚Äî RFM scoring, CLTV, manual segmentation, K-Means clustering, and segment comparison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nILfgJQJ_8N1"
      },
      "source": [
        "### Group Members & Roles\n",
        "\n",
        "| Role | Name | Responsibility |\n",
        "|------|------|----------------|\n",
        "| üñ•Ô∏è **Lead Coder** | | Drives the notebook |\n",
        "| üìä **Data Interpreter** | | Reads outputs, explains what the numbers mean |\n",
        "| üé§ **Presenter** | | Delivers the 3-minute share-out |\n",
        "| ‚úÖ **QA Reviewer** | | Checks outputs against checkpoints |\n",
        "\n",
        "*If 3 members, Lead Coder also handles QA.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCxsWdEP_8N1"
      },
      "source": [
        "<div style=\"background-color: #D6EAF8; border-left: 5px solid #2E86C1; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1A5276;\">üí° GROUP DISCUSSION (before coding ‚Äî 3 minutes)</strong><br>\n",
        "  Your dataset tracks a different type of customer than the UK online retailer from the demo. Before running any code:\n",
        "  <ol>\n",
        "    <li>What does <strong>Recency</strong> mean in this context? What column represents it, or how will you calculate it?</li>\n",
        "    <li>What does <strong>Frequency</strong> mean? Is it the number of orders, visits, or something else?</li>\n",
        "    <li>What does <strong>Monetary</strong> mean? Is it revenue, volume, or a different measure?</li>\n",
        "    <li>Do you expect the Pareto concentration to be more or less extreme than the Online Retail II dataset? Why?</li>\n",
        "  </ol>\n",
        "</div>\n",
        "\n",
        "**Our group's answers (2‚Äì3 sentences per question):**\n",
        "\n",
        "**Sample (Restaurant):** (1) Recency = days since this order's date to the snapshot date. Since each order is treated as a unique customer, Recency reflects when that order occurred. (2) Frequency will be 1 for all orders since each order number is unique ‚Äî this is a limitation of the dataset. (3) Monetary = total order value (Quantity √ó Product Price summed across all items in the order). (4) We expect less extreme Pareto concentration because restaurant orders tend to have a narrower price range than online retail ‚Äî you can't easily spend ¬£10,000 on curry like you can on wholesale goods.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9zJdiU8_8N2"
      },
      "source": [
        "<div style=\"background-color: #D5F5E3; border-left: 5px solid #27AE60; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1E8449;\">‚úÖ DO THIS</strong><br>\n",
        "  Run the setup cell. Then <strong>uncomment ONE dataset option</strong> in the data loading cell and run it.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s3j6m3Q_8N2"
      },
      "source": [
        "# ============================================================\n",
        "# Setup ‚Äî Run this cell. Do not modify.\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "np.random.seed(42)\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
        "plt.rcParams[\"figure.dpi\"] = 100\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Segmentation function from the demo\n",
        "def segment_customer(score):\n",
        "    if score >= 12:\n",
        "        return \"Champions\"\n",
        "    elif score >= 9:\n",
        "        return \"Loyal\"\n",
        "    elif score >= 7:\n",
        "        return \"Potential Loyalist\"\n",
        "    elif score >= 5:\n",
        "        return \"At Risk\"\n",
        "    elif score >= 4:\n",
        "        return \"Can't Lose\"\n",
        "    else:\n",
        "        return \"Lost\"\n",
        "\n",
        "print(\"‚úÖ Setup complete ‚Äî segment_customer() function loaded\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B65JN-la_8N3"
      },
      "source": [
        "# ============================================================\n",
        "# OPTION A ‚Äî Brazilian E-Commerce (Olist) ‚Äî ~100K orders\n",
        "# More challenging: requires merging 3 tables\n",
        "# Uncomment this entire block if choosing Option A\n",
        "# ============================================================\n",
        "# base = \"https://raw.githubusercontent.com/c-marq/cap4767-data-mining/refs/heads/main/data\"\n",
        "# customers = pd.read_csv(f\"{base}/olist_customers_dataset.csv\")\n",
        "# orders = pd.read_csv(f\"{base}/olist_orders_dataset.csv\")\n",
        "# payments = pd.read_csv(f\"{base}/olist_order_payments_dataset.csv\")\n",
        "#\n",
        "# # Merge: orders ‚Üí customers (to get customer_unique_id) ‚Üí payments (to get revenue)\n",
        "# merged = orders.merge(customers, on=\"customer_id\").merge(payments, on=\"order_id\")\n",
        "#\n",
        "# # Use customer_unique_id (not customer_id ‚Äî one person can have multiple customer_ids)\n",
        "# df = merged[[\"customer_unique_id\", \"order_purchase_timestamp\", \"order_id\", \"payment_value\"]].copy()\n",
        "# df.columns = [\"CustomerID\", \"InvoiceDate\", \"InvoiceNo\", \"TotalPrice\"]\n",
        "# df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])\n",
        "# df = df.dropna(subset=[\"CustomerID\"])\n",
        "# df = df[df[\"TotalPrice\"] > 0]\n",
        "# DOMAIN = \"Brazilian E-Commerce\"\n",
        "\n",
        "# ============================================================\n",
        "# OPTION B ‚Äî Restaurant Orders ‚Äî ~1K orders\n",
        "# Simpler, beginner-friendly\n",
        "# Uncomment this entire block if choosing Option B\n",
        "# ============================================================\n",
        "url = \"https://raw.githubusercontent.com/c-marq/cap4767-data-mining/refs/heads/main/data/restaurant-1-orders.csv\"\n",
        "df_raw = pd.read_csv(url)\n",
        "\n",
        "# Restaurant data doesn't have CustomerID ‚Äî use Order Number as proxy\n",
        "# Each order is one \"visit\" ‚Äî Frequency = number of visits\n",
        "df = df_raw.copy()\n",
        "df[\"TotalPrice\"] = df[\"Quantity\"] * df[\"Product Price\"]\n",
        "df[\"InvoiceDate\"] = pd.to_datetime(df[\"Order Date\"], format=\"%d/%m/%Y %H:%M\")\n",
        "df.rename(columns={\"Order Number\": \"InvoiceNo\"}, inplace=True)\n",
        "\n",
        "# Create a CustomerID proxy: since we don't have one, group by Order Number\n",
        "# For this dataset, each order IS a customer visit ‚Äî we'll aggregate at order level first\n",
        "# then treat each unique order as a \"customer\" for RFM\n",
        "# NOTE: This is a simplification ‚Äî discuss with your group why this is a limitation\n",
        "order_summary = df.groupby(\"InvoiceNo\").agg(\n",
        "    InvoiceDate=(\"InvoiceDate\", \"first\"),\n",
        "    TotalPrice=(\"TotalPrice\", \"sum\")\n",
        ").reset_index()\n",
        "order_summary[\"CustomerID\"] = order_summary[\"InvoiceNo\"]  # Each order = unique customer\n",
        "df = order_summary\n",
        "DOMAIN = \"Restaurant Orders\"\n",
        "\n",
        "print(f\"Dataset: {DOMAIN}\")\n",
        "print(f\"Shape: {df.shape[0]:,} rows\")\n",
        "print(f\"Unique customers/orders: {df['CustomerID'].nunique():,}\")\n",
        "print(f\"Date range: {df['InvoiceDate'].min()} to {df['InvoiceDate'].max()}\")\n",
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHfNgmeI_8N3"
      },
      "source": [
        "<div style=\"background-color: #FEF9E7; border-left: 5px solid #F1C40F; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #7D6608;\">‚ö†Ô∏è DATASET NOTES</strong><br>\n",
        "  <ul>\n",
        "    <li><strong>Option A (Olist):</strong> Uses <code>customer_unique_id</code> (not <code>customer_id</code>) because one person can have multiple IDs across orders. Revenue = <code>payment_value</code>.</li>\n",
        "    <li><strong>Option B (Restaurant):</strong> No true CustomerID ‚Äî each order number is treated as a unique customer. This limits RFM interpretation (Frequency will always be 1). Discuss this limitation in your share-out.</li>\n",
        "  </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLLmolFS_8N3"
      },
      "source": [
        "---\n",
        "## Task 1 ‚Äî Calculate RFM Metrics (1 code cell)\n",
        "\n",
        "<div style=\"background-color: #D5F5E3; border-left: 5px solid #27AE60; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1E8449;\">‚úÖ DO THIS</strong><br>\n",
        "  Set a snapshot date (1 day after the last transaction). Use <code>groupby</code> on CustomerID to calculate Recency, Frequency, and Monetary. Print <code>rfm.describe()</code>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCofOCPR_8N3"
      },
      "source": [
        "# Task 1: Calculate RFM metrics\n",
        "snapshot_date = df[\"InvoiceDate\"].max() + pd.Timedelta(days=1)\n",
        "\n",
        "rfm = df.groupby(\"CustomerID\").agg(\n",
        "    Recency=(\"InvoiceDate\", lambda x: (snapshot_date - x.max()).days),\n",
        "    Frequency=(\"InvoiceNo\" if \"InvoiceNo\" in df.columns else \"CustomerID\", \"nunique\"),\n",
        "    Monetary=(\"TotalPrice\", \"sum\")\n",
        ").reset_index()\n",
        "\n",
        "print(f\"Unique customers: {rfm.shape[0]:,}\")\n",
        "print(f\"Snapshot date: {snapshot_date}\")\n",
        "print(f\"\\nRFM Summary:\")\n",
        "print(rfm[[\"Recency\", \"Frequency\", \"Monetary\"]].describe().round(2))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "710k1GhF_8N3"
      },
      "source": [
        "<div style=\"background-color: #FADBD8; border-left: 5px solid #E74C3C; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #922B21;\">üõë CHECKPOINT 1</strong><br>\n",
        "  Your <code>rfm</code> DataFrame should have one row per customer and three numeric columns. Recency should be in days, Frequency should use <code>nunique</code>, Monetary should be a sum.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6MENoQL_8N4"
      },
      "source": [
        "---\n",
        "## Task 2 ‚Äî Assign RFM Scores and Manual Segments (1 code cell)\n",
        "\n",
        "<div style=\"background-color: #D5F5E3; border-left: 5px solid #27AE60; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1E8449;\">‚úÖ DO THIS</strong><br>\n",
        "  Apply <code>pd.qcut()</code> for R, F, M quintile scores (1‚Äì5). Use <code>.rank(method='first')</code> on Frequency if you get a bin-edge error. Calculate composite score. Apply <code>segment_customer()</code>. Print value_counts.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntEh3VIH_8N4"
      },
      "source": [
        "# Task 2: RFM scores + manual segments\n",
        "rfm[\"R_Score\"] = pd.qcut(rfm[\"Recency\"], q=5, labels=[5, 4, 3, 2, 1]).astype(int)\n",
        "rfm[\"F_Score\"] = pd.qcut(rfm[\"Frequency\"].rank(method=\"first\"), q=5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
        "rfm[\"M_Score\"] = pd.qcut(rfm[\"Monetary\"], q=5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
        "rfm[\"RFM_Score\"] = rfm[\"R_Score\"] + rfm[\"F_Score\"] + rfm[\"M_Score\"]\n",
        "\n",
        "rfm[\"Customer_Segment\"] = rfm[\"RFM_Score\"].apply(segment_customer)\n",
        "\n",
        "print(\"Customer Segments:\")\n",
        "print(rfm[\"Customer_Segment\"].value_counts())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1PN84BT_8N4"
      },
      "source": [
        "**Interpretation:** Which segment is largest? Which has the fewest customers? Does this distribution surprise you?\n",
        "\n",
        "**Sample:** Potential Loyalist is the largest segment, which makes sense ‚Äî most restaurant orders fall in the mid-range for both price and recency. Champions is relatively small because truly high-spending orders are rare at a restaurant. The Lost segment is also small since the dataset covers a narrow time window."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVbxaDTr_8N4"
      },
      "source": [
        "<div style=\"background-color: #FADBD8; border-left: 5px solid #E74C3C; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #922B21;\">üõë CHECKPOINT 2</strong><br>\n",
        "  You should have 6 segment labels. If all customers land in one segment, check your qcut labels ‚Äî especially the Recency reversal.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3lYvhrT_8N4"
      },
      "source": [
        "---\n",
        "## Task 3 ‚Äî Scale Features and Run Elbow Method (1 code cell)\n",
        "\n",
        "<div style=\"background-color: #D5F5E3; border-left: 5px solid #27AE60; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1E8449;\">‚úÖ DO THIS</strong><br>\n",
        "  Use <code>StandardScaler</code> on R, F, M scores. Run K-Means for k=2 through k=8. Plot the inertia curve.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnfC2BOr_8N4"
      },
      "source": [
        "# Task 3: Scale + Elbow Method\n",
        "features = rfm[[\"R_Score\", \"F_Score\", \"M_Score\"]]\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "inertias = []\n",
        "k_range = range(2, 9)\n",
        "for k in k_range:\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    km.fit(features_scaled)\n",
        "    inertias.append(km.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(k_range, inertias, \"bo-\", linewidth=2, markersize=8)\n",
        "plt.xlabel(\"Number of Clusters (k)\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.title(\"Elbow Method\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaMF7ZaH_8N4"
      },
      "source": [
        "**Chosen k and justification (1‚Äì2 sentences):**\n",
        "\n",
        "**Sample:** The elbow appears at k=4 ‚Äî the drop from k=3 to k=4 is substantial, then the curve flattens. We chose k=4 because adding a 5th cluster doesn't meaningfully reduce inertia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh_qgL6g_8N4"
      },
      "source": [
        "<div style=\"background-color: #FADBD8; border-left: 5px solid #E74C3C; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #922B21;\">üõë CHECKPOINT 3</strong><br>\n",
        "  Your elbow plot should show a clear curve. If it's a straight line, check that you're using the scaled features, not the raw values.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovM4u-5y_8N4"
      },
      "source": [
        "---\n",
        "## Task 4 ‚Äî Fit K-Means and Profile Clusters (1 code cell)\n",
        "\n",
        "<div style=\"background-color: #D5F5E3; border-left: 5px solid #27AE60; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1E8449;\">‚úÖ DO THIS</strong><br>\n",
        "  Fit K-Means with your chosen k. Add cluster labels to <code>rfm</code>. Create a cluster profiling heatmap (mean R, F, M per cluster). Print cluster sizes.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7_c--vC_8N5"
      },
      "source": [
        "# Task 4: K-Means + profiling heatmap\n",
        "optimal_k = 4  # Adjust based on your elbow plot\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "rfm[\"Cluster\"] = kmeans.fit_predict(features_scaled)\n",
        "\n",
        "print(f\"Cluster sizes (k={optimal_k}):\")\n",
        "print(rfm[\"Cluster\"].value_counts().sort_index())\n",
        "\n",
        "# Profiling heatmap\n",
        "cluster_profile = rfm.groupby(\"Cluster\")[[\"R_Score\", \"F_Score\", \"M_Score\"]].mean()\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(cluster_profile, annot=True, fmt=\".2f\", cmap=\"YlOrRd\",\n",
        "            xticklabels=[\"Recency\", \"Frequency\", \"Monetary\"], linewidths=0.5)\n",
        "plt.title(\"Cluster Profiles ‚Äî Mean RFM Scores\")\n",
        "plt.ylabel(\"Cluster\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx6i9fvc_8N5"
      },
      "source": [
        "**Name each cluster (1 sentence per cluster):**\n",
        "\n",
        "**Sample:** Cluster 0: 'Big Spenders' ‚Äî high M, moderate R and F. Cluster 1: 'Recent Light Buyers' ‚Äî high R, low M. Cluster 2: 'Lapsed Customers' ‚Äî low R, low F, low M. Cluster 3: 'Core Regulars' ‚Äî moderate across all three dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO5qPfLx_8N5"
      },
      "source": [
        "---\n",
        "## Task 5 ‚Äî Compare Manual Segments vs K-Means (1 code cell)\n",
        "\n",
        "<div style=\"background-color: #D5F5E3; border-left: 5px solid #27AE60; padding: 15px; margin: 15px 0; border-radius: 4px;\">\n",
        "  <strong style=\"color: #1E8449;\">‚úÖ DO THIS</strong><br>\n",
        "  Build a crosstab: <code>pd.crosstab(rfm[\"Customer_Segment\"], rfm[\"Cluster\"], margins=True)</code>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6TKn2YJ_8N5"
      },
      "source": [
        "# Task 5: Crosstab comparison\n",
        "crosstab = pd.crosstab(rfm[\"Customer_Segment\"], rfm[\"Cluster\"], margins=True)\n",
        "print(\"Manual Segments (rows) vs K-Means Clusters (columns):\")\n",
        "print(crosstab)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK01nm-y_8N5"
      },
      "source": [
        "**Interpretation (2‚Äì3 sentences):** Where do the two approaches agree? Where do they disagree? Did K-Means discover a sub-group within one of the manual segments?\n",
        "\n",
        "**Sample:** The two methods agree that the highest-scoring customers (Champions) cluster together. They disagree on the mid-range ‚Äî the 'At Risk' manual segment is split across two clusters, one with higher Monetary and one with lower. K-Means separated 'At Risk customers who spent a lot but haven't returned' from 'At Risk customers who barely spent and haven't returned' ‚Äî the manual rules lumped them together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyczR5sN_8N5"
      },
      "source": [
        "---\n",
        "## Six Success Criteria Questions\n",
        "\n",
        "Answer each in 1‚Äì3 sentences:\n",
        "\n",
        "1. **How many unique customers are in your dataset after cleaning?**\n",
        "2. **What percentage of customers fall into the top two RFM segments (Champions + Loyal)?**\n",
        "3. **What is the ratio of mean to median Monetary value?** (Revenue concentration indicator)\n",
        "4. **How many clusters did the Elbow Method suggest, and do you agree?**\n",
        "5. **Which K-Means cluster represents the highest-value customers, and how many are in it?**\n",
        "6. **Did K-Means reveal a group that the manual rules missed or split?** Describe it.\n",
        "\n",
        "**Sample answers:**\n",
        "1. ~660 unique orders after cleaning.\n",
        "2. Champions + Loyal ‚âà 35‚Äì40% of the base.\n",
        "3. Mean/Median Monetary ratio ‚âà 1.4x ‚Äî less extreme than Online Retail because restaurant orders have a narrower price range.\n",
        "4. Elbow suggests k=4, and we agree ‚Äî the curve clearly flattens after 4.\n",
        "5. Cluster 0 (Big Spenders) ‚Äî approximately 150 customers with the highest average Monetary scores.\n",
        "6. K-Means split the At Risk segment into two distinct groups: one with high historical spend (worth a win-back campaign) and one with minimal spend (lower priority). The manual rules treated them identically.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIHVfZZi_8N5"
      },
      "source": [
        "## Share-Out (3 minutes)\n",
        "\n",
        "Present to the class:\n",
        "1. Which dataset your group used and how you mapped R, F, M\n",
        "2. Your most interesting finding from manual segmentation\n",
        "3. Your most interesting finding from K-Means\n",
        "4. One recommendation a business could act on based on your segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T61OQ-1_8N5"
      },
      "source": [
        "## Troubleshooting\n",
        "\n",
        "| Problem | Fix |\n",
        "|---------|-----|\n",
        "| `pd.qcut` error: \"Bin edges must be unique\" | Add `.rank(method='first')` before qcut |\n",
        "| All customers in one segment | Check Recency label reversal: `labels=[5,4,3,2,1]` |\n",
        "| Olist merge gives empty DataFrame | Check column names: `customer_id` (not `CustomerID`) in merge |\n",
        "| Elbow plot is a straight line | Use scaled features, not raw scores |\n",
        "| Restaurant Frequency is all 1 | Expected ‚Äî each order is a unique \"customer.\" Discuss as a limitation. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou6jAkl8_8N5"
      },
      "source": [
        "---\n",
        "<p style=\"color:#7F8C8D; font-size:0.85em;\">\n",
        "<em>CAP4767 Data Mining with Python | Miami Dade College | Spring 2026</em><br>\n",
        "Week 5 Group Exercise ‚Äî RFM + K-Means on a New Dataset | 10 Points\n",
        "</p>"
      ]
    }
  ]
}